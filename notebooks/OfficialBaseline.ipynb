{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-04T04:21:44.294009Z",
     "start_time": "2022-06-04T04:21:44.285005Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drzon/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from typing import Callable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "from paddle.io import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1>训练阶段</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>准备超参数</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-04T04:21:44.310473Z",
     "start_time": "2022-06-04T04:21:44.300349Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prep_env():\n",
    "    # type: () -> dict\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Prepare the experimental settings\n",
    "    Returns:\n",
    "        The initialized arguments\n",
    "    \"\"\"\n",
    "    settings = {\n",
    "        \"path_to_test_x\": \"../data/sdwpf_baidukddcup2022_test_toy/test_x\",\n",
    "        \"path_to_test_y\": \"../data/sdwpf_baidukddcup2022_test_toy/test_y\",\n",
    "        \"data_path\": \"../data\",\n",
    "        \"filename\": \"wtbdata_245days.csv\",\n",
    "        \"task\": \"MS\",\n",
    "        \"target\": \"Patv\",\n",
    "        \"checkpoints\": \"models\",\n",
    "        \"input_len\": 144,\n",
    "        \"output_len\": 288,\n",
    "        \"start_col\": 3,\n",
    "        \"in_var\": 10,\n",
    "        \"out_var\": 1,\n",
    "        \"day_len\": 144,\n",
    "        \"train_size\": 153,\n",
    "        \"val_size\": 16,\n",
    "        \"test_size\": 15,\n",
    "        \"total_size\": 245,\n",
    "        \"lstm_layer\": 2,\n",
    "        \"dropout\": 0.05,\n",
    "        \"num_workers\": 5,\n",
    "        \"train_epochs\": 10,\n",
    "        \"batch_size\": 32,\n",
    "        \"patience\": 3,\n",
    "        \"lr\": 1e-4,\n",
    "        \"lr_adjust\": \"type1\",\n",
    "        \"gpu\": 0,\n",
    "        \"capacity\": 134,\n",
    "        \"turbine_id\": 0,\n",
    "        \"pred_file\": \"predict.py\",\n",
    "        \"framework\": \"paddlepaddle\",\n",
    "        \"is_debug\": True\n",
    "    }\n",
    "    ###\n",
    "    # Prepare the GPUs\n",
    "    if paddle.device.is_compiled_with_cuda():\n",
    "        settings[\"use_gpu\"] = True\n",
    "        paddle.device.set_device('gpu:{}'.format(settings[\"gpu\"]))\n",
    "    else:\n",
    "        settings[\"use_gpu\"] = False\n",
    "        paddle.device.set_device('cpu')\n",
    "\n",
    "    print(\"The experimental settings are: \\n{}\".format(str(settings)))\n",
    "    return settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>准备模型</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-04T04:21:44.321453Z",
     "start_time": "2022-06-04T04:21:44.313592Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BaselineGruModel(nn.Layer):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        A simple GRU model\n",
    "    \"\"\"\n",
    "    def __init__(self, settings):\n",
    "        # type: (dict) -> None\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            __init__\n",
    "        Args:\n",
    "            settings: a dict of parameters\n",
    "        \"\"\"\n",
    "        super(BaselineGruModel, self).__init__()\n",
    "        self.output_len = settings[\"output_len\"]\n",
    "        self.hidC = settings[\"in_var\"]\n",
    "        self.hidR = 48\n",
    "        self.out_dim = settings[\"out_var\"]\n",
    "        self.dropout = nn.Dropout(settings[\"dropout\"])\n",
    "        self.lstm = nn.GRU(input_size=self.hidC, hidden_size=self.hidR, num_layers=settings[\"lstm_layer\"],\n",
    "                           time_major=True)\n",
    "        self.projection = nn.Linear(self.hidR, self.out_dim)\n",
    "\n",
    "    def forward(self, x_enc):\n",
    "        # type: (paddle.tensor) -> paddle.tensor\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            The specific implementation for interface forward\n",
    "        Args:\n",
    "            x_enc:\n",
    "        Returns:\n",
    "            A tensor\n",
    "        \"\"\"\n",
    "        # 修改：查看前向传播\n",
    "#         print(\"--------------\")\n",
    "#         print(x_enc.shape)\n",
    "        \n",
    "        x = paddle.zeros([x_enc.shape[0], self.output_len, x_enc.shape[2]])\n",
    "        x_enc = paddle.concat((x_enc, x), 1)\n",
    "        \n",
    "#         print(x_enc.shape)\n",
    "        \n",
    "        x_enc = paddle.transpose(x_enc, perm=(1, 0, 2))\n",
    "        dec, _ = self.lstm(x_enc)\n",
    "        dec = paddle.transpose(dec, perm=(1, 0, 2))\n",
    "        sample = self.projection(self.dropout(dec))\n",
    "        \n",
    "#         print(sample.shape)\n",
    "        sample = sample[:, -self.output_len:, -self.out_dim:]\n",
    "        \n",
    "        # 修改：查看前向传播过程\n",
    "#         print(sample.shape)\n",
    "#         print(\"--------------\")\n",
    "        return sample  # [B, L, D]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>准备标准化</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-04T04:21:44.329105Z",
     "start_time": "2022-06-04T04:21:44.323814Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Scaler(object):\n",
    "    \"\"\"\n",
    "    Desc: Normalization utilities\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.mean = 0.\n",
    "        self.std = 1.\n",
    "\n",
    "    def fit(self, data):\n",
    "        # type: (paddle.tensor) -> None\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            Fit the data\n",
    "        Args:\n",
    "            data:\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.mean = np.mean(data)\n",
    "        self.std = np.std(data)\n",
    "\n",
    "    def transform(self, data):\n",
    "        # type: (paddle.tensor) -> paddle.tensor\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            Transform the data\n",
    "        Args:\n",
    "            data:\n",
    "        Returns:\n",
    "            The transformed data\n",
    "        \"\"\"\n",
    "        mean = paddle.to_tensor(self.mean).type_as(data).to(data.device) if paddle.is_tensor(data) else self.mean\n",
    "        std = paddle.to_tensor(self.std).type_as(data).to(data.device) if paddle.is_tensor(data) else self.std\n",
    "        return (data - mean) / std\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        # type: (paddle.tensor) -> paddle.tensor\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            Restore to the original data\n",
    "        Args:\n",
    "            data: the transformed data\n",
    "        Returns:\n",
    "            The original data\n",
    "        \"\"\"\n",
    "        mean = paddle.to_tensor(self.mean) if paddle.is_tensor(data) else self.mean\n",
    "        std = paddle.to_tensor(self.std) if paddle.is_tensor(data) else self.std\n",
    "        return (data * std) + mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>准备数据集</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-04T04:21:44.342200Z",
     "start_time": "2022-06-04T04:21:44.330797Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class WindTurbineDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Desc: Data preprocessing,\n",
    "          Here, e.g.    15 days for training,\n",
    "                        3 days for validation,\n",
    "                        and 6 days for testing\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path,\n",
    "                 filename='my.csv',\n",
    "                 flag='train',\n",
    "                 size=None,\n",
    "                 turbine_id=0,\n",
    "                 task='MS',\n",
    "                 target='Target',\n",
    "                 scale=True,\n",
    "                 start_col=2,       # the start column index of the data one aims to utilize\n",
    "                 day_len=24 * 6,\n",
    "                 train_days=15,     # 15 days\n",
    "                 val_days=3,        # 3 days\n",
    "                 test_days=6,       # 6 days\n",
    "                 total_days=30      # 30 days\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.unit_size = day_len\n",
    "        if size is None:\n",
    "            self.input_len = self.unit_size\n",
    "            self.output_len = self.unit_size\n",
    "        else:\n",
    "            self.input_len = size[0]\n",
    "            self.output_len = size[1]\n",
    "        # initialization\n",
    "        assert flag in ['train', 'test', 'val']\n",
    "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
    "        self.set_type = type_map[flag]\n",
    "        self.task = task\n",
    "        self.target = target\n",
    "        self.scale = scale\n",
    "        self.start_col = start_col\n",
    "        self.data_path = data_path\n",
    "        self.filename = filename\n",
    "        self.tid = turbine_id\n",
    "\n",
    "        # If needed, we employ the predefined total_size (e.g. one month)\n",
    "        self.total_size = self.unit_size * total_days\n",
    "        #\n",
    "        self.train_size = train_days * self.unit_size\n",
    "        self.val_size = val_days * self.unit_size\n",
    "        self.test_size = test_days * self.unit_size\n",
    "        # self.test_size = self.total_size - train_size - val_size\n",
    "        #\n",
    "        # Or, if total_size is unavailable:\n",
    "        # self.total_size = self.train_size + self.val_size + self.test_size\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler = Scaler()\n",
    "        df_raw = pd.read_csv(os.path.join(self.data_path, self.filename))\n",
    "        border1s = [self.tid * self.total_size,\n",
    "                    self.tid * self.total_size + self.train_size - self.input_len,\n",
    "                    self.tid * self.total_size + self.train_size + self.val_size - self.input_len\n",
    "                    ]\n",
    "        border2s = [self.tid * self.total_size + self.train_size,\n",
    "                    self.tid * self.total_size + self.train_size + self.val_size,\n",
    "                    self.tid * self.total_size + self.train_size + self.val_size + self.test_size\n",
    "                    ]\n",
    "        border1 = border1s[self.set_type]\n",
    "        border2 = border2s[self.set_type]\n",
    "\n",
    "        df_data = df_raw\n",
    "        if self.task == 'M':\n",
    "            cols_data = df_raw.columns[self.start_col:]\n",
    "            df_data = df_raw[cols_data]\n",
    "        elif self.task == 'MS':\n",
    "            cols_data = df_raw.columns[self.start_col:]\n",
    "            df_data = df_raw[cols_data]\n",
    "        elif self.task == 'S':\n",
    "            df_data = df_raw[[self.tid, self.target]]\n",
    "\n",
    "        # Turn off the SettingWithCopyWarning\n",
    "        pd.set_option('mode.chained_assignment', None)\n",
    "        df_data.replace(to_replace=np.nan, value=0, inplace=True)\n",
    "\n",
    "        if self.scale:\n",
    "            train_data = df_data[border1s[0]:border2s[0]]            \n",
    "            self.scaler.fit(train_data.values)\n",
    "            data = self.scaler.transform(df_data.values)\n",
    "        else:\n",
    "            data = df_data.values\n",
    "        self.data_x = data[border1:border2]\n",
    "        self.data_y = data[border1:border2]\n",
    "        self.raw_data = df_data[border1 + self.input_len:border2]\n",
    "\n",
    "    def get_raw_data(self):\n",
    "        return self.raw_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #\n",
    "        # Only for customized use.\n",
    "        # When sliding window not used, e.g. prediction without overlapped input/output sequences\n",
    "        if self.set_type >= 3:\n",
    "            index = index * self.output_len\n",
    "        #\n",
    "        # Standard use goes here.\n",
    "        # Sliding window with the size of input_len + output_len\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.input_len\n",
    "        r_begin = s_end\n",
    "        r_end = r_begin + self.output_len\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        seq_y = self.data_y[r_begin:r_end]\n",
    "        return seq_x, seq_y\n",
    "\n",
    "    def __len__(self):\n",
    "        # In our case, the sliding window is adopted, the number of samples is calculated as follows\n",
    "        if self.set_type < 3:\n",
    "            return len(self.data_x) - self.input_len - self.output_len + 1\n",
    "        # Otherwise, if sliding window is not adopted\n",
    "        return int((len(self.data_x) - self.input_len) / self.output_len)\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>调整学习率</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-04T04:21:44.348302Z",
     "start_time": "2022-06-04T04:21:44.344079Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    # type: (paddle.optimizer.Adam, int, dict) -> None\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Adjust learning rate\n",
    "    Args:\n",
    "        optimizer:\n",
    "        epoch:\n",
    "        args:\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # lr = args.lr * (0.2 ** (epoch // 2))\n",
    "    lr_adjust = {}\n",
    "    if args[\"lr_adjust\"] == 'type1':\n",
    "        # learning_rate = 0.5^{epoch-1}\n",
    "        lr_adjust = {epoch: args[\"lr\"] * (0.50 ** (epoch - 1))}\n",
    "    elif args[\"lr_adjust\"] == 'type2':\n",
    "        lr_adjust = {\n",
    "            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "            10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "        }\n",
    "    if epoch in lr_adjust:\n",
    "        lr = lr_adjust[epoch]\n",
    "        optimizer.set_lr(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>EarlyStop</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-04T04:21:44.354619Z",
     "start_time": "2022-06-04T04:21:44.350196Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EarlyStopping(object):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        EarlyStopping\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.best_model = False\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, path, tid):\n",
    "        # type: (nn.MSELoss, BaselineGruModel, str, int) -> None\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            Save current checkpoint\n",
    "        Args:\n",
    "            val_loss: the validation loss\n",
    "            model: the model\n",
    "            path: the path to be saved\n",
    "            tid: turbine ID\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.best_model = True\n",
    "        self.val_loss_min = val_loss\n",
    "        paddle.save(model.state_dict(), path + '/' + 'model_' + str(tid))\n",
    "\n",
    "    def __call__(self, val_loss, model, path, tid):\n",
    "        # type: (nn.MSELoss, BaselineGruModel, str, int) -> None\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            __call__\n",
    "        Args:\n",
    "            val_loss: the validation loss\n",
    "            model: the model\n",
    "            path: the path to be saved\n",
    "            tid: turbine ID\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path, tid)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.best_model = False\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.update_hidden = True\n",
    "            self.save_checkpoint(val_loss, model, path, tid)\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>实验操作</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-04T04:21:44.364305Z",
     "start_time": "2022-06-04T04:21:44.355961Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Experiment(object):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        The experiment to train, validate and test a model\n",
    "    \"\"\"\n",
    "    def __init__(self, args):\n",
    "        # type: (dict) -> None\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            __init__\n",
    "        Args:\n",
    "            args: the arguments to initialize the experimental environment\n",
    "        \"\"\"\n",
    "        self.model = BaselineGruModel(args)\n",
    "        self.args = args\n",
    "\n",
    "    def get_model(self):\n",
    "        # type: () -> BaselineGruModel\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            the model\n",
    "        Returns:\n",
    "            An instance of the model\n",
    "        \"\"\"\n",
    "        return self.model\n",
    "\n",
    "    def get_args(self):\n",
    "        # type: () -> dict\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            Get the arguments\n",
    "        Returns:\n",
    "            A dict\n",
    "        \"\"\"\n",
    "        return self.args\n",
    "\n",
    "    def get_data(self, flag):\n",
    "        # type: (str) -> (WindTurbineDataset, DataLoader)\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            get_data\n",
    "        Args:\n",
    "            flag: train or test\n",
    "        Returns:\n",
    "            A dataset and a dataloader\n",
    "        \"\"\"\n",
    "        if flag == 'test':\n",
    "            shuffle_flag = False\n",
    "            drop_last = True\n",
    "        else:\n",
    "            shuffle_flag = True\n",
    "            drop_last = True\n",
    "        data_set = WindTurbineDataset(\n",
    "            data_path=self.args[\"data_path\"],\n",
    "            filename=self.args[\"filename\"],\n",
    "            flag=flag,\n",
    "            size=[self.args[\"input_len\"], self.args[\"output_len\"]],\n",
    "            task=self.args[\"task\"],\n",
    "            target=self.args[\"target\"],\n",
    "            start_col=self.args[\"start_col\"],\n",
    "            turbine_id=self.args[\"turbine_id\"],\n",
    "            day_len=self.args[\"day_len\"],\n",
    "            train_days=self.args[\"train_size\"],\n",
    "            val_days=self.args[\"val_size\"],\n",
    "            test_days=self.args[\"test_size\"],\n",
    "            total_days=self.args[\"total_size\"]\n",
    "        )\n",
    "        data_loader = DataLoader(\n",
    "            data_set,\n",
    "            batch_size=self.args[\"batch_size\"],\n",
    "            shuffle=shuffle_flag,\n",
    "            num_workers=self.args[\"num_workers\"],\n",
    "            drop_last=drop_last\n",
    "        )\n",
    "        return data_set, data_loader\n",
    "\n",
    "    def load_train_data(self):\n",
    "        # type: () -> WindTurbineData\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            Load train data to get the scaler for testing\n",
    "        Returns:\n",
    "            The train set\n",
    "        \"\"\"\n",
    "        train_data = WindTurbineData(\n",
    "            data_path=self.args[\"data_path\"],\n",
    "            filename=self.args[\"filename\"],\n",
    "            flag='train',\n",
    "            size=[self.args[\"input_len\"], self.args[\"output_len\"]],\n",
    "            task=self.args[\"task\"],\n",
    "            target=self.args[\"target\"],\n",
    "            start_col=self.args[\"start_col\"],\n",
    "            day_len=self.args[\"day_len\"],\n",
    "            train_days=self.args[\"train_size\"],\n",
    "            val_days=self.args[\"val_size\"],\n",
    "            total_days=self.args[\"total_size\"],\n",
    "            is_test=True\n",
    "        )\n",
    "        return train_data\n",
    "\n",
    "    @staticmethod\n",
    "    def get_test_x(args):\n",
    "        # type: (dict) -> TestData\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            Obtain the input sequence for testing\n",
    "        Args:\n",
    "            args:\n",
    "        Returns:\n",
    "            Normalized input sequences and training data\n",
    "        \"\"\"\n",
    "        test_x = TestData(path_to_data=args[\"path_to_test_x\"], farm_capacity=args[\"capacity\"])\n",
    "        return test_x\n",
    "\n",
    "    def inference_one_sample(self, model, sample_x):\n",
    "        # type: (BaselineGruModel, paddle.tensor) -> paddle.tensor\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            Inference one sample\n",
    "        Args:\n",
    "            model:\n",
    "            sample_x:\n",
    "        Returns:\n",
    "            Predicted sequence with sample_x as input\n",
    "        \"\"\"\n",
    "        x = sample_x.astype('float32')\n",
    "        prediction = model(x)\n",
    "        f_dim = -1 if self.args[\"task\"] == 'MS' else 0\n",
    "        return prediction[..., :, f_dim:].astype('float32')\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        # type: () -> paddle.optimizer.Adam\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            Get the optimizer\n",
    "        Returns:\n",
    "            An optimizer\n",
    "        \"\"\"\n",
    "        clip = paddle.nn.ClipGradByNorm(clip_norm=50.0)\n",
    "        model_optim = paddle.optimizer.Adam(parameters=self.model.parameters(),\n",
    "                                            learning_rate=self.args[\"lr\"],\n",
    "                                            grad_clip=clip)\n",
    "        return model_optim\n",
    "\n",
    "    @staticmethod\n",
    "    def get_criterion():\n",
    "        # type: () -> nn.MSELoss\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            Use the mse loss as the criterion\n",
    "        Returns:\n",
    "            MSE loss\n",
    "        \"\"\"\n",
    "        criterion = nn.MSELoss(reduction='mean')\n",
    "        return criterion\n",
    "\n",
    "    def process_one_batch(self, batch_x, batch_y):\n",
    "        # type: (paddle.tensor, paddle.tensor) -> (paddle.tensor, paddle.tensor)\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            Process a batch\n",
    "        Args:\n",
    "            batch_x:\n",
    "            batch_y:\n",
    "        Returns:\n",
    "            prediction and ground truth\n",
    "        \"\"\"\n",
    "        batch_x = batch_x.astype('float32')\n",
    "        batch_y = batch_y.astype('float32')\n",
    "        sample = self.model(batch_x)\n",
    "        #\n",
    "        # If the task is the multivariate-to-univariate forecasting task,\n",
    "        # the last column is the target variable to be predicted\n",
    "        f_dim = -1 if self.args[\"task\"] == 'MS' else 0\n",
    "        #\n",
    "        batch_y = batch_y[:, -self.args[\"output_len\"]:, f_dim:].astype('float32')\n",
    "        sample = sample[:, :, f_dim:].astype('float32')\n",
    "        return sample, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>遍历样本</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-04T04:21:44.370870Z",
     "start_time": "2022-06-04T04:21:44.365728Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def traverse_wind_farm(method, params, model_path, flag='train'):\n",
    "    # type: (Callable, dict, str, str) -> list\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Traverse the turbines in a wind farm on by one\n",
    "    Args:\n",
    "        method: the method for training or testing on the records of one turbine\n",
    "        params: the arguments initialized\n",
    "        model_path: the folder name of the model\n",
    "        flag: 'train' or 'test'\n",
    "    Returns:\n",
    "        Predictions (for test) or None\n",
    "    \"\"\"\n",
    "    responses = []\n",
    "    start_time = time.time()\n",
    "    for i in range(params[\"capacity\"]):\n",
    "        params[\"turbine_id\"] = i\n",
    "        exp = Experiment(params)\n",
    "        if 'train' == flag:\n",
    "            print('>>>>>>> Training Turbine {:3d} >>>>>>>>>>>>>>>>>>>>>>>>>>\\n'.format(i))\n",
    "            method(exp, model_path, is_debug=params[\"is_debug\"])\n",
    "        elif 'test' == flag:\n",
    "            print('>>>>>>> Forecasting Turbine {:3d} >>>>>>>>>>>>>>>>>>>>>>>>>>\\n'.format(i))\n",
    "            res = method(exp, model_path)\n",
    "            responses.append(res)\n",
    "        else:\n",
    "            pass\n",
    "        paddle.device.cuda.empty_cache()\n",
    "        if params[\"is_debug\"]:\n",
    "            end_time = time.time()\n",
    "            print(\"Elapsed time for {} turbine {} is {} secs\".format(\"training\" if \"train\" == flag else \"predicting\", i,\n",
    "                                                                     end_time - start_time))\n",
    "            start_time = end_time\n",
    "        \n",
    "        # 修改：只遍历一个样本\n",
    "        break\n",
    "    if 'test' == flag:\n",
    "        return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>验证</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-04T04:21:44.377801Z",
     "start_time": "2022-06-04T04:21:44.372129Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def val(experiment, data_loader, criterion):\n",
    "    # type: (Experiment, DataLoader, Callable) -> np.array\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Validation function\n",
    "    Args:\n",
    "        experiment:\n",
    "        data_loader:\n",
    "        criterion:\n",
    "    Returns:\n",
    "        The validation loss\n",
    "    \"\"\"\n",
    "    validation_loss = []\n",
    "    for i, (batch_x, batch_y) in enumerate(data_loader):\n",
    "        sample, true = experiment.process_one_batch(batch_x, batch_y)\n",
    "        loss = criterion(sample, true)\n",
    "        validation_loss.append(loss.item())\n",
    "    validation_loss = np.average(validation_loss)\n",
    "    return validation_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>训练并验证</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-04T04:21:44.383813Z",
     "start_time": "2022-06-04T04:21:44.378854Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_val(experiment, model_folder, is_debug=False):\n",
    "    # type: (Experiment, str, bool) -> None\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "        Training and validation\n",
    "    Args:\n",
    "        experiment:\n",
    "        model_folder: folder name of the model\n",
    "        is_debug:\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    args = experiment.get_args()\n",
    "    model = experiment.get_model()\n",
    "    train_data, train_loader = experiment.get_data(flag='train')\n",
    "    val_data, val_loader = experiment.get_data(flag='val')\n",
    "\n",
    "    path_to_model = os.path.join(args[\"checkpoints\"], model_folder)\n",
    "    if not os.path.exists(path_to_model):\n",
    "        os.makedirs(path_to_model)\n",
    "\n",
    "    time_now = time.time()\n",
    "    early_stopping = EarlyStopping(patience=args[\"patience\"], verbose=True)\n",
    "    model_optim = experiment.get_optimizer()\n",
    "    criterion = Experiment.get_criterion()\n",
    "\n",
    "    epoch_start_time = time.time()\n",
    "    for epoch in range(args[\"train_epochs\"]):\n",
    "        iter_count = 0\n",
    "        train_loss = []\n",
    "        model.train()\n",
    "        for i, (batch_x, batch_y) in enumerate(train_loader):\n",
    "            # 修改：我要查看一下样本长什么样子\n",
    "#             print(batch_x)\n",
    "#             print(batch_y)\n",
    "            \n",
    "            iter_count += 1\n",
    "            sample, truth = experiment.process_one_batch(batch_x, batch_y)\n",
    "            \n",
    "            # 修改：我要查看一下输出是什么样子\n",
    "#             print(sample)\n",
    "#             print(truth)\n",
    "            \n",
    "            loss = criterion(sample, truth)\n",
    "            train_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            model_optim.minimize(loss)\n",
    "            model_optim.step()\n",
    "        val_loss = val(experiment, val_loader, criterion)\n",
    "\n",
    "        if is_debug:\n",
    "            train_loss = np.average(train_loss)\n",
    "            epoch_end_time = time.time()\n",
    "            print(\"Epoch: {}, \\nTrain Loss: {}, \\nValidation Loss: {}\".format(epoch, train_loss, val_loss))\n",
    "            print(\"Elapsed time for epoch-{}: {}\".format(epoch, epoch_end_time - epoch_start_time))\n",
    "            epoch_start_time = epoch_end_time\n",
    "\n",
    "        # Early Stopping if needed\n",
    "        early_stopping(val_loss, model, path_to_model, args[\"turbine_id\"])\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopped! \")\n",
    "            break\n",
    "        adjust_learning_rate(model_optim, epoch + 1, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>开始训练</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-04T04:21:57.576654Z",
     "start_time": "2022-06-04T04:21:44.384870Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experimental settings are: \n",
      "{'path_to_test_x': '../data/sdwpf_baidukddcup2022_test_toy/test_x', 'path_to_test_y': '../data/sdwpf_baidukddcup2022_test_toy/test_y', 'data_path': '../data', 'filename': 'wtbdata_245days.csv', 'task': 'MS', 'target': 'Patv', 'checkpoints': 'models', 'input_len': 144, 'output_len': 288, 'start_col': 3, 'in_var': 10, 'out_var': 1, 'day_len': 144, 'train_size': 153, 'val_size': 16, 'test_size': 15, 'total_size': 245, 'lstm_layer': 2, 'dropout': 0.05, 'num_workers': 5, 'train_epochs': 10, 'batch_size': 32, 'patience': 3, 'lr': 0.0001, 'lr_adjust': 'type1', 'gpu': 0, 'capacity': 134, 'turbine_id': 0, 'pred_file': 'predict.py', 'framework': 'paddlepaddle', 'is_debug': True, 'use_gpu': True}\n",
      ">>>>>>> Training Turbine   0 >>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "(22032, 10)\n",
      "(22032, 10)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c1871f17a0d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtraverse_wind_farm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_and_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_setup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-466cc6abf7c5>\u001b[0m in \u001b[0;36mtraverse_wind_farm\u001b[0;34m(method, params, model_path, flag)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>>>>>>> Training Turbine {:3d} >>>>>>>>>>>>>>>>>>>>>>>>>>\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_debug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"is_debug\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m'test'\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>>>>>>> Forecasting Turbine {:3d} >>>>>>>>>>>>>>>>>>>>>>>>>>\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-5306e7cf784a>\u001b[0m in \u001b[0;36mtrain_and_val\u001b[0;34m(experiment, model_folder, is_debug)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mmodel_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mmodel_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-248>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad_tensor, retain_graph)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/paddle/fluid/wrapped_decorator.py\u001b[0m in \u001b[0;36m__impl__\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mwrapped_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/paddle/fluid/framework.py\u001b[0m in \u001b[0;36m__impl__\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m         assert in_dygraph_mode(\n\u001b[1;32m    226\u001b[0m         ), \"We only support '%s()' in dynamic graph mode, please call 'paddle.disable_static()' to enter dynamic graph mode.\" % func.__name__\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad_tensor, retain_graph)\u001b[0m\n\u001b[1;32m    236\u001b[0m                                           framework._dygraph_tracer())\n\u001b[1;32m    237\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m                 core.dygraph_run_backward([self], [grad_tensor], retain_graph,\n\u001b[0m\u001b[1;32m    239\u001b[0m                                           framework._dygraph_tracer())\n\u001b[1;32m    240\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "settings = prep_env()\n",
    "\n",
    "# Set up the initial environment\n",
    "# Current settings for the model\n",
    "cur_setup = '{}_t{}_i{}_o{}_ls{}_train{}_val{}'.format(\n",
    "    settings[\"filename\"], settings[\"task\"], settings[\"input_len\"], settings[\"output_len\"], settings[\"lstm_layer\"],\n",
    "    settings[\"train_size\"], settings[\"val_size\"]\n",
    ")\n",
    "\n",
    "traverse_wind_farm(train_and_val, settings, cur_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
